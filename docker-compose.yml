version: '3.9'

x-common-volumes: &airflow-vols
  - ./airflow/dags:/opt/airflow/dags
  - ./pipeline:/opt/airflow/pipeline
  - ./airflow/logs:/opt/airflow/logs
  - ./airflow/plugins:/opt/airflow/plugins

# ⬇⬇⬇ BLOQUE COMÚN DE VARIABLES PARA AIRFLOW ⬇⬇⬇
x-airflow-env: &airflow-env
  AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
  AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
  AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow

  AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
  AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
  AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}

services:

  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - ./postgres/data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  minio:
    image: minio/minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: admin123
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./minio/data:/data

  redis:
    image: redis:7

  airflow-init:
    image: airflow:custom_lu
    depends_on:
      - postgres
      - redis
    environment:
      <<: *airflow-env
      PYTHONPATH: "/opt/airflow/pipeline"
    user: "50000:0"
    volumes: *airflow-vols
    entrypoint: /bin/bash -c "
      airflow db init &&
      airflow users create --username admin --password admin123 --role Admin \
      --firstname admin --lastname admin --email admin@example.com"
    env_file:
      - .env

  airflow-webserver:
    image: airflow:custom_lu
    depends_on:
      - airflow-init
      - postgres
      - redis
      - minio
    environment:
      <<: *airflow-env
      PYTHONPATH: "/opt/airflow/pipeline"
    user: "50000:0"
    ports:
      - "8080:8080"
    volumes: *airflow-vols
    command: webserver
    env_file:
      - .env

  airflow-scheduler:
    image: airflow:custom_lu
    depends_on:
      - airflow-webserver
    environment:
      <<: *airflow-env
    user: "50000:0"
    volumes: *airflow-vols
    command: scheduler
    env_file:
      - .env

  airflow-worker:
    image: airflow:custom_lu
    depends_on:
      - airflow-webserver
    environment:
      <<: *airflow-env
    user: "50000:0"
    volumes: *airflow-vols
    command: celery worker
    env_file:
      - .env

  airflow-triggerer:
    image: airflow:custom_lu
    depends_on:
      - airflow-webserver
    environment:
      <<: *airflow-env
    user: "50000:0"
    volumes: *airflow-vols
    command: triggerer
    env_file:
      - .env

volumes:
  postgres_data:


# version: '3.9'

# x-common-volumes: &airflow-vols
#   - ./airflow/dags:/opt/airflow/dags
#   - ./pipeline:/opt/airflow/pipeline
#   - ./airflow/logs:/opt/airflow/logs
#   - ./airflow/plugins:/opt/airflow/plugins
# services:

#   postgres:
#     image: postgres:15
#     environment:
#       POSTGRES_USER: airflow
#       POSTGRES_PASSWORD: airflow
#       POSTGRES_DB: airflow
#     volumes:
#       - ./postgres/data:/var/lib/postgresql/data
#     ports:
#       - "5432:5432"

#   minio:
#     image: minio/minio
#     command: server /data --console-address ":9001"
#     environment:
#       MINIO_ROOT_USER: admin
#       MINIO_ROOT_PASSWORD: admin123
#     ports:
#       - "9000:9000"
#       - "9001:9001"
#     volumes:
#       - ./minio/data:/data

#   redis:
#     image: redis:7

#   airflow-init:
#     build:
#       context: .
#       dockerfile: Dockerfile
#     image: airflow:custom_lu
#     depends_on:
#       - postgres
#       - redis
#     environment:
#       AIRFLOW__CORE__EXECUTOR: CeleryExecutor
#       AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
#       PYTHONPATH: "/opt/airflow/pipeline"
#     user: "50000:0"
#     volumes: *airflow-vols
#       # - ./airflow/dags:/opt/airflow/dags
#       # - ./airflow/logs:/opt/airflow/logs
#       # - ./airflow/plugins:/opt/airflow/plugins
#     entrypoint: /bin/bash -c "
#       airflow db init &&
#       airflow users create --username admin --password admin --role Admin \
#       --firstname admin --lastname admin --email admin@example.com"
#     env_file:
#       - .env

#   airflow-webserver:
#     image: airflow:custom_lu
#     depends_on:
#       - airflow-init
#       - postgres
#       - redis
#       - minio
#     environment:
#       AIRFLOW__CORE__EXECUTOR: CeleryExecutor
#       AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
#       AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
#       AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
#       PYTHONPATH: "/opt/airflow/pipeline"
#     user: "50000:0"
#     ports:
#       - "8080:8080"
#     volumes: *airflow-vols
#       # - ./airflow/dags:/opt/airflow/dags
#       # - ./airflow/logs:/opt/airflow/logs
#       # - ./airflow/plugins:/opt/airflow/plugins
#     command: webserver
#     env_file:
#       - .env

#   airflow-scheduler:
#     image: airflow:custom_lu
#     depends_on:
#       - airflow-webserver
#     environment:
#       AIRFLOW__CORE__EXECUTOR: CeleryExecutor
#       AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
#       AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
#       AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
#     user: "50000:0"
#     volumes: *airflow-vols
#       #      - ./airflow/dags:/opt/airflow/dags
#       # - ./airflow/logs:/opt/airflow/logs
#       # - ./airflow/plugins:/opt/airflow/plugins
#     command: scheduler
#     env_file:
#       - .env

#   airflow-worker:
#     image: airflow:custom_lu
#     depends_on:
#       - airflow-webserver
#     environment:
#       AIRFLOW__CORE__EXECUTOR: CeleryExecutor
#       AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
#       AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
#       AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
#     user: "50000:0"
#     volumes: *airflow-vols
#       # - ./airflow/dags:/opt/airflow/dags
#       # - ./airflow/logs:/opt/airflow/logs
#       # - ./airflow/plugins:/opt/airflow/plugins
#     command: celery worker
#     env_file:
#       - .env

#   airflow-triggerer:
#     image: airflow:custom_lu
#     depends_on:
#       - airflow-webserver
#     environment:
#       AIRFLOW__CORE__EXECUTOR: CeleryExecutor
#       AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
#       AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
#       AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
#     user: "50000:0"
#     volumes: *airflow-vols
#       # - ./airflow/dags:/opt/airflow/dags
#       # - ./airflow/logs:/opt/airflow/logs
#       # - ./airflow/plugins:/opt/airflow/plugins
#     command: triggerer
#     env_file:
#       - .env

# volumes:
#   postgres_data:


